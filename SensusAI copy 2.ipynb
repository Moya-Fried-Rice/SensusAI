{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0074760-1d1f-4803-821b-dd14ef218b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's good</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love this app so much, I've been using Spoti...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best all around music streaming app I have use...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are y'all fr gatekeeping the play button on so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84160</th>\n",
       "      <td>The most decent music streaming app around rig...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84161</th>\n",
       "      <td>As a premium user for a few years, Spotify is ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84162</th>\n",
       "      <td>There is lot of ads all of a sudden, and it's ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84163</th>\n",
       "      <td>The UI could be better. I think there should b...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84164</th>\n",
       "      <td>It was good till I couldn't listen to the musi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84165 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  score\n",
       "0                                              It's good      4\n",
       "1      I love this app so much, I've been using Spoti...      5\n",
       "2                                                Perfect      5\n",
       "3      Best all around music streaming app I have use...      5\n",
       "4      Are y'all fr gatekeeping the play button on so...      1\n",
       "...                                                  ...    ...\n",
       "84160  The most decent music streaming app around rig...      3\n",
       "84161  As a premium user for a few years, Spotify is ...      4\n",
       "84162  There is lot of ads all of a sudden, and it's ...      3\n",
       "84163  The UI could be better. I think there should b...      4\n",
       "84164  It was good till I couldn't listen to the musi...      1\n",
       "\n",
       "[84165 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# Read the CSV file (fixed the quotes)\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\abcjv\\\\Downloads\\\\spotify_reviews.csv\", usecols=['content', 'score'])\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fd4f0c-49a4-412e-bfad-dbf03256bd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's good</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love this app so much, I've been using Spoti...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best all around music streaming app I have use...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are y'all fr gatekeeping the play button on so...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84160</th>\n",
       "      <td>The most decent music streaming app around rig...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84161</th>\n",
       "      <td>As a premium user for a few years, Spotify is ...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84162</th>\n",
       "      <td>There is lot of ads all of a sudden, and it's ...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84163</th>\n",
       "      <td>The UI could be better. I think there should b...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84164</th>\n",
       "      <td>It was good till I couldn't listen to the musi...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  score sentiment\n",
       "0                                              It's good      4  positive\n",
       "1      I love this app so much, I've been using Spoti...      5  positive\n",
       "2                                                Perfect      5  positive\n",
       "3      Best all around music streaming app I have use...      5  positive\n",
       "4      Are y'all fr gatekeeping the play button on so...      1  negative\n",
       "...                                                  ...    ...       ...\n",
       "84160  The most decent music streaming app around rig...      3   neutral\n",
       "84161  As a premium user for a few years, Spotify is ...      4  positive\n",
       "84162  There is lot of ads all of a sudden, and it's ...      3   neutral\n",
       "84163  The UI could be better. I think there should b...      4  positive\n",
       "84164  It was good till I couldn't listen to the musi...      1  negative\n",
       "\n",
       "[84165 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to convert rating stars to sentiment\n",
    "def stars_to_sentiment(stars):\n",
    "    if stars <= 2:\n",
    "        return 'negative'\n",
    "    elif stars == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "# Ensure 'score' column exists before applying\n",
    "if 'score' in df.columns:\n",
    "    df['sentiment'] = df['score'].apply(stars_to_sentiment)\n",
    "else:\n",
    "    print(\"Error: Column 'score' not found in DataFrame.\")\n",
    "\n",
    "# Correct way to select multiple columns\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6b3fb7-5425-4f31-91a1-532e6e780f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's good</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love this app so much, I've been using Spoti...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>love app much ive use spotify year different a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best all around music streaming app I have use...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>best around music stream app use family plan g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are y'all fr gatekeeping the play button on so...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>yall fr gatekeeping play button song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84160</th>\n",
       "      <td>The most decent music streaming app around rig...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>decent music stream app around right kink ridi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84161</th>\n",
       "      <td>As a premium user for a few years, Spotify is ...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>premium user year spotify fantastic service us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84162</th>\n",
       "      <td>There is lot of ads all of a sudden, and it's ...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>lot ad sudden even watch video want uninterrup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84163</th>\n",
       "      <td>The UI could be better. I think there should b...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>ui could good think should search bar time lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84164</th>\n",
       "      <td>It was good till I couldn't listen to the musi...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>good till could not listen music want set play...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84165 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  score sentiment  \\\n",
       "0                                              It's good      4  positive   \n",
       "1      I love this app so much, I've been using Spoti...      5  positive   \n",
       "2                                                Perfect      5  positive   \n",
       "3      Best all around music streaming app I have use...      5  positive   \n",
       "4      Are y'all fr gatekeeping the play button on so...      1  negative   \n",
       "...                                                  ...    ...       ...   \n",
       "84160  The most decent music streaming app around rig...      3   neutral   \n",
       "84161  As a premium user for a few years, Spotify is ...      4  positive   \n",
       "84162  There is lot of ads all of a sudden, and it's ...      3   neutral   \n",
       "84163  The UI could be better. I think there should b...      4  positive   \n",
       "84164  It was good till I couldn't listen to the musi...      1  negative   \n",
       "\n",
       "                                       processed_content  \n",
       "0                                                   good  \n",
       "1      love app much ive use spotify year different a...  \n",
       "2                                                perfect  \n",
       "3      best around music stream app use family plan g...  \n",
       "4                   yall fr gatekeeping play button song  \n",
       "...                                                  ...  \n",
       "84160  decent music stream app around right kink ridi...  \n",
       "84161  premium user year spotify fantastic service us...  \n",
       "84162  lot ad sudden even watch video want uninterrup...  \n",
       "84163  ui could good think should search bar time lik...  \n",
       "84164  good till could not listen music want set play...  \n",
       "\n",
       "[84165 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Ensure necessary NLTK resources are downloaded\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Contraction words\n",
    "contractions = {\n",
    "    \"isn't\": \"is not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"hadn't\": \"had not\", \"isn't\": \"is not\",\n",
    "    \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\", \"needn't\": \"need not\", \"needn't\": \"need not\", \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\", \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\", \"there's\": \"there is\", \"they'd\": \"they would\", \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\", \"they've\": \"they have\", \"wasn't\": \"was not\", \"weren't\": \"were not\",\n",
    "    \"what's\": \"what is\", \"what'll\": \"what will\", \"what're\": \"what are\", \"what've\": \"what have\",\n",
    "    \"where's\": \"where is\", \"where've\": \"where have\", \"who's\": \"who is\", \"who'll\": \"who will\",\n",
    "    \"who're\": \"who are\", \"who've\": \"who have\", \"why's\": \"why is\", \"why're\": \"why are\",\n",
    "    \"why've\": \"why have\", \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "# Important words\n",
    "sentiment_important_words = {\n",
    "    \"not\", \"no\", \"very\", \"good\", \"bad\", \"excellent\", \"love\", \"hate\", \"great\", \"feel\", \"wish\", \"would\", \"should\"\n",
    "}\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to NOUN if unknown\n",
    "    \n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Expand contractions (assumes contractions dictionary is available)\n",
    "    for contraction, expansion in contractions.items():\n",
    "        text = text.replace(contraction, expansion)\n",
    "\n",
    "    # Remove punctuation using regular expressions\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Initialize the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Define English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Customize the stopwords list for sentiment analysis (add negations or important words)\n",
    "    stop_words = stop_words - sentiment_important_words  # Remove sentiment important words from stopwords\n",
    "\n",
    "    # POS tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    # Apply lemmatization based on POS tags and filter out stopwords and single-letter words\n",
    "    lemmatized_tokens = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags\n",
    "        if word.isalnum() and word not in stop_words and len(word) > 1  # Filter single-letter words\n",
    "    ]\n",
    "\n",
    "    # Join the lemmatized tokens back into a single string\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Test the function\n",
    "df['processed_content'] = df['content'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e65968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation Functions\n",
    "import random\n",
    "\n",
    "def get_synonym(word):\n",
    "    \"\"\"\n",
    "    Returns a synonym for the given word that is different from the original word.\n",
    "    If no synonym is found, returns the original word.\n",
    "    \"\"\"\n",
    "    word_lower = word.lower()\n",
    "    \n",
    "    try:\n",
    "        synsets = wordnet.synsets(word)\n",
    "        for synset in synsets:\n",
    "            for lemma in synset.lemmas():\n",
    "                lemma_name = lemma.name().lower()\n",
    "                if lemma_name != word_lower:  # Ensure the synonym is different\n",
    "                    return lemma.name().replace(\"_\", \" \")  # Replace underscores with spaces\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{word}': {e}\")\n",
    "    \n",
    "    return word  # Return original if no different synonym is found\n",
    "\n",
    "def replace_random_words(sentence, num_words=2):\n",
    "    \"\"\"\n",
    "    Replaces a specified number of random words in the sentence with their synonyms.\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    if not words:\n",
    "        return sentence\n",
    "\n",
    "    # Randomly select indices to replace, ensuring we don't exceed the number of words\n",
    "    replace_indices = random.sample(range(len(words)), min(num_words, len(words)))\n",
    "    \n",
    "    for index in replace_indices:\n",
    "        words[index] = get_synonym(words[index].lower())  # Convert to lowercase for matching\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_random_words(sentence, num_words=2):\n",
    "    \"\"\"\n",
    "    Removes random words from the sentence, prioritizing less important words.\n",
    "    Does not remove words from the contractions dictionary or sentiment_important_words set.\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(sentence)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    # Define important POS tags for sentiment (adjectives, verbs, adverbs, nouns)\n",
    "    important_tags = {'JJ', 'JJR', 'JJS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'RB', 'RBR', 'RBS'}\n",
    "\n",
    "    # Combine contractions and sentiment-important words into a single set\n",
    "    protected_words = set(contractions.keys()).union(sentiment_important_words)\n",
    "\n",
    "    # Separate important and removable words\n",
    "    removable_words = [\n",
    "        word for word, tag in pos_tags\n",
    "        if tag not in important_tags  # Not in important POS tags\n",
    "        and word.lower() not in stopwords.words('english')  # Not a stopword\n",
    "        and word.lower() not in protected_words  # Not in protected words\n",
    "    ]\n",
    "\n",
    "    # Remove up to `num_words` random removable words\n",
    "    words_to_remove = random.sample(removable_words, min(num_words, len(removable_words)))\n",
    "\n",
    "    # Filter out the words to remove\n",
    "    filtered_tokens = [word for word in tokens if word not in words_to_remove]\n",
    "\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "def random_insertion(sentence, num_insertions=2):\n",
    "    \"\"\"\n",
    "    Inserts a synonym of a random word into the sentence at a random position.\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(sentence)\n",
    "    non_stopwords = [word for word in tokens if word.lower() not in stopwords.words('english') and word.isalpha()]\n",
    "    \n",
    "    if not non_stopwords:\n",
    "        return sentence  # No valid word found\n",
    "\n",
    "    for _ in range(num_insertions):\n",
    "        random_word = random.choice(non_stopwords)  # Pick a random non-stopword\n",
    "        synonym = get_synonym(random_word)  # Get a synonym\n",
    "\n",
    "        if not synonym or synonym.lower() == random_word.lower():\n",
    "            continue  # Skip if no suitable synonym found\n",
    "\n",
    "        insert_position = random.randint(0, len(tokens))  # Pick a random position\n",
    "        tokens.insert(insert_position, synonym)  # Insert synonym at random position\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def random_swapping(sentence, num_swaps=2):\n",
    "    tokens = word_tokenize(sentence)  # Tokenize the sentence\n",
    "    words = [word for word in tokens if word.lower() not in stopwords.words('english') and word.isalpha()]\n",
    "    \n",
    "    if len(words) < 2:\n",
    "        return sentence  # Not enough words to swap\n",
    "\n",
    "    for _ in range(num_swaps):\n",
    "        # Select two random non-stopwords\n",
    "        word1, word2 = random.sample(words, 2)\n",
    "\n",
    "        # Find their positions in the original token list\n",
    "        index1, index2 = tokens.index(word1), tokens.index(word2)\n",
    "\n",
    "        # Swap their positions in the original tokens\n",
    "        tokens[index1], tokens[index2] = tokens[index2], tokens[index1]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def apply_augmentations(sentence):\n",
    "    \"\"\"\n",
    "    Augments the sentence based on its length by applying random replacement, removal, insertion, and swapping.\n",
    "    \"\"\"\n",
    "    # Preprocess the text (this includes lemmatization, stopword removal, etc.)\n",
    "    preprocessed_sentence = preprocess_text(sentence)\n",
    "    \n",
    "    # Calculate the number of augmentations to perform based on sentence length\n",
    "    num_words = len(preprocessed_sentence.split())\n",
    "    \n",
    "    # Determine how many augmentations to apply based on sentence length\n",
    "    num_replacements = max(1, num_words // 2)  # Adjust as needed\n",
    "    num_removals = max(1, num_words // 8)  # Adjust as needed\n",
    "    num_insertions = max(1, num_words // 8)  # Adjust as needed\n",
    "    num_swaps = max(1, num_words // 10)  # Adjust as needed\n",
    "\n",
    "    # Apply augmentations based on calculated values\n",
    "    sentence = replace_random_words(preprocessed_sentence, num_words=num_replacements)\n",
    "    sentence = remove_random_words(sentence, num_words=num_removals)\n",
    "    sentence = random_insertion(sentence, num_insertions=num_insertions)\n",
    "    sentence = random_swapping(sentence, num_swaps=num_swaps)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5ee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing word 'listen': \n",
      "Error processing word 'tried': \n",
      "Error processing word 'membership': \n",
      "Error processing word 'truly': \n",
      "Error processing word 'restrict': \n",
      "Error processing word 'best': \n",
      "Error processing word 'artist': \n",
      "Error processing word 'ever': \n",
      "Error processing word 'great': \n",
      "Error processing word 'truly': \n",
      "Error processing word 'favorite': \n",
      "Error processing word 'music': \n",
      "Error processing word 'music': \n",
      "Error processing word 'favorite': \n",
      "Error processing word 'yes': \n",
      "Error processing word 'yes': \n",
      "Error processing word 'however': \n",
      "Error processing word 'randomly': \n",
      "Error processing word 'window': \n",
      "Error processing word 'reopen': \n",
      "Error processing word 'constantly': \n",
      "Error processing word 'music': \n",
      "Error processing word 'run': \n",
      "Error processing word 'very': \n",
      "Error processing word 'best': \n",
      "Error processing word 'technically': \n",
      "Error processing word 'background': \n",
      "Error processing word 'stop': \n",
      "Error processing word 'throw': \n",
      "Error processing word 'year': \n",
      "Error processing word 'use': \n",
      "Error processing word 'love': \n",
      "Error processing word 'screen': \n",
      "Error processing word 'cut': \n",
      "Error processing word 'case': \n",
      "Error processing word 'year': \n",
      "Error processing word 'restart': \n",
      "Error processing word 'randomly': \n",
      "Error processing word 'constantly': \n",
      "Error processing word 'like': \n",
      "Error processing word 'great': \n",
      "Error processing word 'not': \n",
      "Error processing word 'lot': \n",
      "Error processing word 'good': \n",
      "Error processing word 'wifi': \n",
      "Error processing word 'need': \n",
      "Error processing word 'need': \n",
      "Error processing word 'set': \n",
      "Error processing word 'thing': \n",
      "Error processing word 'audio': \n",
      "Error processing word 'use': \n",
      "Error processing word 'include': \n",
      "Error processing word 'use': \n",
      "Error processing word 'love': \n",
      "Error processing word 'audio': \n",
      "Error processing word 'wifi': \n",
      "Error processing word 'clear': \n",
      "Error processing word 'play': \n",
      "Error processing word 'notification': \n",
      "Error processing word 'auto': \n",
      "Error processing word 'gravy': \n",
      "Error processing word 'try': \n",
      "Error processing word 'notification': \n",
      "Error processing word 'no': \n",
      "Error processing word 'one': \n",
      "Error processing word 'problem': \n",
      "Error processing word 'auto': \n",
      "Error processing word 'put': \n",
      "Error processing word 'fix': \n",
      "Error processing word 'even': \n",
      "Error processing word 'problem': \n",
      "Error processing word 'try': \n",
      "Error processing word 'otherwise': \n",
      "Error processing word 'one': \n",
      "Error processing word 'gravy': \n",
      "Error processing word 'hiccup': \n",
      "Error processing word 'recently': \n",
      "Error processing word 'time': \n",
      "Error processing word 'least': \n",
      "Error processing word 'not': \n",
      "Error processing word 'freeze': \n",
      "Error processing word 'not': \n",
      "Error processing word 'give': \n",
      "Error processing word 'change': \n",
      "Error processing word 'never': \n",
      "Error processing word 'close': \n",
      "Error processing word 'even': \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "\n",
    "# Function to oversample and augment the data\n",
    "def oversample_and_augment(sentiment_class, target_size, apply_augmentations):\n",
    "    \"\"\"\n",
    "    Oversamples a sentiment class to the target size while keeping original data unchanged.\n",
    "    Only newly generated samples receive augmentations.\n",
    "    \"\"\"\n",
    "    num_original = len(sentiment_class)\n",
    "    num_new_samples = target_size - num_original  # Number of new samples needed\n",
    "\n",
    "    # Generate new samples using resampling\n",
    "    new_samples = resample(sentiment_class, replace=True, n_samples=num_new_samples, random_state=42)\n",
    "\n",
    "    # Apply augmentation only to the new samples\n",
    "    new_samples = new_samples.copy()  # Ensure original DataFrame is not modified\n",
    "    new_samples['processed_content'] = new_samples['processed_content'].apply(apply_augmentations)\n",
    "\n",
    "    # Combine original and new samples\n",
    "    return pd.concat([sentiment_class, new_samples])\n",
    "\n",
    "# Assuming 'df' is your original DataFrame\n",
    "# Separate the data by sentiment\n",
    "negative_samples = df[df['sentiment'] == 'negative']\n",
    "neutral_samples = df[df['sentiment'] == 'neutral']\n",
    "positive_samples = df[df['sentiment'] == 'positive']\n",
    "\n",
    "# The target size for neutral and positive classes will be 1.5 times the size of the negative class\n",
    "target_size_neutral_positive = int(len(negative_samples) * 1.5)\n",
    "\n",
    "# Create a thread pool to process the classes in parallel\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    futures.append(executor.submit(oversample_and_augment, neutral_samples, target_size_neutral_positive, apply_augmentations))\n",
    "    futures.append(executor.submit(oversample_and_augment, positive_samples, target_size_neutral_positive, apply_augmentations))\n",
    "\n",
    "    # Collect the results\n",
    "    neutral_oversampled = futures[0].result()\n",
    "    positive_oversampled = futures[1].result()\n",
    "\n",
    "# Combine the original negative samples with the oversampled neutral and positive samples\n",
    "balanced_df = pd.concat([negative_samples, neutral_oversampled, positive_oversampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(balanced_df['sentiment'].value_counts())  # Check class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6e7c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'balanced_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Count the number of occurrences for each sentiment category\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m sentiment_count = \u001b[43mbalanced_df\u001b[49m[\u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n\u001b[32m      7\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m))  \u001b[38;5;66;03m# Set the figure size\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Create a pie chart to visualize sentiment distribution\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'balanced_df' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Count the number of occurrences for each sentiment category\n",
    "sentiment_count = balanced_df['sentiment'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 8))  # Set the figure size\n",
    "\n",
    "# Create a pie chart to visualize sentiment distribution\n",
    "plt.pie(sentiment_count, labels=sentiment_count.index, autopct=\"%1.1f%%\", startangle=140)\n",
    "\n",
    "plt.title('Sentiment Distribution')  # Add a title to the chart\n",
    "plt.axis('equal')  # Ensure the pie chart is displayed as a circle\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_df['processed_content'], balanced_df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer with bigrams, minimum document frequency of 3, and max document frequency of 90%\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=5, max_df=0.9, sublinear_tf=True)\n",
    "\n",
    "# Fit the vectorizer on training data and transform it into numerical feature vectors\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted vectorizer\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8a9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99      9848\n",
      "     neutral       0.79      0.88      0.83     14686\n",
      "    positive       0.85      0.76      0.81     14591\n",
      "\n",
      "    accuracy                           0.86     39125\n",
      "   macro avg       0.88      0.88      0.88     39125\n",
      "weighted avg       0.87      0.86      0.86     39125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_vectorized, y_train)\n",
    "preds = rf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review):\n",
    "    processed_review = preprocess_text(review)\n",
    "    vectorized_review = vectorizer.transform([processed_review])\n",
    "    sentiment = rf.predict(vectorized_review)[0]\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e17e1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_sentiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m new_review = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33mI hate it\u001b[39m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredicted sentiment:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mpredict_sentiment\u001b[49m(new_review))\n",
      "\u001b[31mNameError\u001b[39m: name 'predict_sentiment' is not defined"
     ]
    }
   ],
   "source": [
    "new_review = \"\"\"\n",
    "\n",
    "I hate it\n",
    "\n",
    "\"\"\"\n",
    "print(\"Predicted sentiment:\", predict_sentiment(new_review))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
